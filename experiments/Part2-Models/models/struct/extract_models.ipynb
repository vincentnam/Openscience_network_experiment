{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-18T15:43:57.591022857Z",
     "start_time": "2023-09-18T15:43:57.547196058Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import os\n",
    "\n",
    "from lxml import etree\n",
    "import dateparser\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "# TODO : Format date to interrop doc\n",
    "\n",
    "def get_all_keys(doc, main_key=None, separator=\".\", key_list = [], first_call=True):\n",
    "    '''\n",
    "    Get all key and sub key of a document, sub key are constructed with a separator defined as a parameter.\n",
    "    :param doc:\n",
    "    :param main_key:\n",
    "    :param separator:\n",
    "    :param first_call\n",
    "    :return:\n",
    "    '''\n",
    "    if isinstance(doc, type({})):\n",
    "\n",
    "        for key in  doc.keys():\n",
    "            if main_key is None :\n",
    "                key_list.append(key)\n",
    "                get_all_keys(doc[key],main_key=key, separator=separator, key_list=key_list, first_call=False)\n",
    "            else :\n",
    "                key_list.append(main_key+separator+key)\n",
    "                get_all_keys(doc[key],main_key=main_key+separator+key, separator=separator, key_list=key_list, first_call=False)\n",
    "    if isinstance(doc, type([])):\n",
    "        for obj in doc:\n",
    "            if isinstance(obj, type({})):\n",
    "                for key in  obj.keys():\n",
    "                    if main_key is None :\n",
    "                        key_list.append(key)\n",
    "                        get_all_keys(obj[key],main_key=key, separator=separator, key_list=key_list, first_call=False)\n",
    "                    else :\n",
    "                        key_list.append(main_key+separator+key)\n",
    "                        get_all_keys(obj[key],main_key=main_key+separator+key, separator=separator, key_list=key_list, first_call=False)\n",
    "\n",
    "    return key_list\n",
    "\n",
    "\n",
    "def remove_id_in_json(f_json):\n",
    "    \"\"\"\n",
    "    As mongoDB id or _id is reserved keyword, this function modify any field that is \"id\" or \"_id\" to add \"doc\" before.\n",
    "    :param f_json: dict containing a parsed json\n",
    "    :return: dict : f_json with a modified \"id\" or \"_id\" key if there was\n",
    "    \"\"\"\n",
    "    key_list = [\"id\",\"_id\"]\n",
    "    if index_key_list:=[index for index, key_is_present in enumerate([key in f_json for key in key_list ]) if key_is_present]:\n",
    "        for index in index_key_list :\n",
    "            f_json[\"doc_\"+ key_list[index]]= f_json.pop( key_list[index])\n",
    "    return f_json\n",
    "\n",
    "def format_date_json(doc):\n",
    "    if type(doc) is dict:\n",
    "        for key in doc.keys():\n",
    "            if (type(doc[key]) is str) and (date := dateparser.parse(doc[key])) is not None:\n",
    "                    doc[key]=date\n",
    "            format_date_json(doc[key])\n",
    "    if type(doc) is list:\n",
    "        for object in doc :\n",
    "            format_date_json(object)\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "def read_preprocess_insert_in_mongodb_json(fp, mongodb_coll=None, fp_is_dict=False):\n",
    "    \"\"\"\n",
    "    Read, remove any incompatible \"id\" key and insert the JSON in a collection in a mongodb database\n",
    "    :param fp: str : file_path to a JSON to read\n",
    "    :param mongodb_coll: MongoClient.database.collection : A collection in which insert files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if mongodb_coll is None:\n",
    "        mongodb_coll = MongoClient(\"localhost:27017\").no_model_name.interop_metadata\n",
    "\n",
    "    try:\n",
    "        # mongodb_coll.insert_one(format_date_json(remove_id_in_json(json.load(open(fp)))))\n",
    "        # Error seens in data formatting\n",
    "        if fp_is_dict:\n",
    "            mongodb_coll.insert_one((remove_id_in_json(fp)))\n",
    "        else:\n",
    "            mongodb_coll.insert_one((remove_id_in_json(json.load(open(fp)))))\n",
    "        # print(fp + \" has been inserted successfully.\")\n",
    "    except Exception as exce :\n",
    "        print(\"Insertion has not been successfully done. Logs : \" + str(exce))\n",
    "\n",
    "def dont_contains_dict(liste):\n",
    "    for elem in liste :\n",
    "        # print(elem)\n",
    "        if type(elem) is dict:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Transform a date to standard format\n",
    "def format_date(date):\n",
    "    # Transform a string date into a standard format by trying each\n",
    "    # date format. If you want to add a format, add a try/except in the\n",
    "    # last except\n",
    "    # date : str : the date to transform\n",
    "    # return : m : timedata : format is YYYY-MM-DD HH:MM:SS\n",
    "    date_str = date\n",
    "    #\n",
    "    date_str = date_str.replace(\"st\",\"\").replace(\"th\",\"\")\\\n",
    "        .replace(\"nd\",\"\").replace(\"rd\",\"\").replace(\" Augu \",\" Aug \")\n",
    "    m = None\n",
    "    sep_list = [\".\",\"/\",\"-\",\"_\",\" \",\":\"]\n",
    "    for date_sep in sep_list:\n",
    "        try:\n",
    "            m = datetime.datetime.strptime(date_str, \"%d\"+date_sep+\"%B\"+date_sep+\"%Y\")\n",
    "            break\n",
    "        except ValueError:\n",
    "            try:\n",
    "                m = datetime.datetime.strptime(date_str, \"%d\"+date_sep+\"%b\"+date_sep+\"%Y\")\n",
    "                break\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    m = datetime.datetime.strptime(date_str, \"%Y\"+date_sep+\"%m\"+date_sep+\"%d\")\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    try :\n",
    "                        m = datetime.datetime.strptime(date_str,\n",
    "                                                   \"%d\"+date_sep+\"%m\"+date_sep+\"%Y\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        for hour_sep in sep_list:\n",
    "                            try:\n",
    "                                m = datetime.datetime\\\n",
    "                                    .strptime(date_str,\"%d\"+date_sep+\"%m\"+date_sep+\"%Y %H\"+hour_sep+\"%M\"+hour_sep+\"%S\")\n",
    "                                break\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    m = datetime.datetime\\\n",
    "                                        .strptime(date_str, \"%Y\"+date_sep+\"%m\"+date_sep+\"%d %H\"+hour_sep+\"%M\"+hour_sep+\"%S\")\n",
    "                                    break\n",
    "                                except ValueError:\n",
    "                                    # HERE ADD A FORMAT TO CHECK\n",
    "                                    # print(\"Format not recognised. \\nConsider \"\n",
    "                                    #       \"adding a date format \"\n",
    "                                    #       \"in the function \\\"format_date\\\".\")\n",
    "                                    pass\n",
    "\n",
    "    return m\n",
    "\n",
    "def XML_to_dict(xml):\n",
    "    xml_tag = re.sub(\"{.*}\",\"\",xml.tag)\n",
    "    res_dict ={xml_tag:{}}\n",
    "    path = [xml_tag]\n",
    "    def tree_walk(xml, path):\n",
    "        aux_path = path\n",
    "        for child in xml.getchildren():\n",
    "            child_tag=re.sub(\"{.*}\",\"\",child.tag)\n",
    "            aux = res_dict\n",
    "            for i in path:\n",
    "                aux = aux[i]\n",
    "            if child_tag in aux:\n",
    "                for attr in child.attrib:\n",
    "\n",
    "                    if re.sub(\"{.*}\",\"\",attr) in aux[child_tag]:\n",
    "\n",
    "                        if isinstance(aux[child_tag][re.sub(\"{.*}\",\"\",attr)], list):\n",
    "                            aux[child_tag][re.sub(\"{.*}\",\"\",attr)].append(child.attrib[attr])\n",
    "                        else :\n",
    "                            aux[child_tag][re.sub(\"{.*}\",\"\",attr)] = [aux[child_tag][re.sub(\"{.*}\",\"\",attr)]] + [child.attrib[attr]]\n",
    "                    else :\n",
    "                        aux[child_tag][re.sub(\"{.*}\",\"\",attr)] = child.attrib[attr]\n",
    "                if isinstance(child.text,str):\n",
    "                    if child.text.strip():\n",
    "                        if \"@value\" in aux[child_tag]:\n",
    "                            if isinstance(aux[child_tag][\"@value\"],list):\n",
    "\n",
    "                                        aux[child_tag][\"@value\"].append(child.text)\n",
    "                            else:\n",
    "                                aux[child_tag][\"@value\"]=[aux[child_tag][\"@value\"]]+[child.text]\n",
    "                        else:\n",
    "                            aux[child_tag][\"@value\"]=child.text\n",
    "            else:\n",
    "                aux[child_tag]={}\n",
    "                for attr in child.attrib:\n",
    "                    aux[child_tag][re.sub(\"{.*}\",\"\",attr)]=child.attrib[attr]\n",
    "                if isinstance(child.text,str):\n",
    "                    if child.text.strip():\n",
    "                        aux[child_tag][\"@value\"]=child.text\n",
    "            tree_walk(child, aux_path+[child_tag])\n",
    "    for child in xml.getchildren():\n",
    "        child_tag=re.sub(\"{.*}\",\"\",child.tag)\n",
    "        if child_tag in res_dict[xml_tag]:\n",
    "            for attr in child.attrib:\n",
    "                if re.sub(\"{.*}\",\"\",attr) in res_dict[xml_tag][child_tag]:\n",
    "                    if isinstance(res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)], list):\n",
    "                        res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)].append(child.attrib[attr])\n",
    "                    else:\n",
    "                        res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)] = [res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)]] + [child.attrib[attr]]\n",
    "                else:\n",
    "                    res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)]=child.attrib[attr]\n",
    "            if isinstance(child.text,str):\n",
    "                if child.text.strip():\n",
    "                    if \"@value\" in res_dict[xml_tag][child_tag]:\n",
    "                        if isinstance(res_dict[xml_tag][child_tag][\"@value\"],list):\n",
    "                                    res_dict[xml_tag][child_tag][\"@value\"].append(child.text)\n",
    "                        else:\n",
    "                            res_dict[xml_tag][child_tag][\"@value\"]=[res_dict[xml_tag][child_tag][\"@value\"]]+[child.text]\n",
    "                    else:\n",
    "                        res_dict[xml_tag][child_tag][\"@value\"]=child.text\n",
    "        else:\n",
    "            res_dict[xml_tag][child_tag]={}\n",
    "            for attr in child.attrib:\n",
    "                res_dict[xml_tag][child_tag][re.sub(\"{.*}\",\"\",attr)]=child.attrib[attr]\n",
    "            if isinstance(child.text,str):\n",
    "                if child.text.strip():\n",
    "                    if \"@value\" in res_dict[xml_tag][child_tag]:\n",
    "                        if isinstance(res_dict[xml_tag][child_tag][\"@value\"],list):\n",
    "                            res_dict[xml_tag][child_tag][\"@value\"].append(child.text.strip())\n",
    "                        else:\n",
    "                            res_dict[xml_tag][child_tag][\"@value\"]=res_dict[xml_tag][child_tag][\"@value\"]+[child.text]\n",
    "\n",
    "                    else:\n",
    "                        res_dict[xml_tag][child_tag][\"@value\"]=child.text\n",
    "        tree_walk(child, path+[child_tag])\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def from_keyset_to_csv(key_set, separator=\".\"):\n",
    "    color = {\"0\":\"#F3722C\",\"1\":\"#F8961E\",\"2\":\"#F9C74F\",\"3\":\"#90BE6D\", \"4\":\"#43AA8B\",\"5\":\"#4D908E\",\"6\":\"#577590\",\"7\":\"#277DA1\", \"8\":\"#bdd5ea\", \"9\":\"#e3e2e3\",\"10\":\"#ffffff\", \"11\":\"#ffffff\"}\n",
    "    csv_list = [(\"ROOT_NODE\",\"\",-1,\"#F94144\")]\n",
    "    for key_concat in key_set:\n",
    "        key_split = key_concat.split(separator)\n",
    "        for index in range(len(key_split)):\n",
    "            if index <9:\n",
    "                if len(key_split)==1:\n",
    "                    csv_list.append((separator.join(key_split[:index+1]),\"ROOT_NODE\", index, color[str(index)]))\n",
    "                    break\n",
    "                if index == len(key_split) -1:\n",
    "                    break\n",
    "                csv_list.append((separator.join(key_split[:index+2]),separator.join(key_split[:index+1]),index+1, color[str(index+1)]))\n",
    "\n",
    "            else :\n",
    "                if index == len(key_split) -1:\n",
    "                    break\n",
    "                csv_list.append((separator.join(key_split[:index+2]),separator.join(key_split[:index+1]),index+1,\"#ffffff\"))\n",
    "    return ([\"key\",\"mother_key\", \"level\",\"color\"],set(csv_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Need for a MongoDB database running on the host listening on port 27017 (tested with docker container)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b6c2c811f470b65"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DarwinCore\n",
      "PREMIS\n",
      "AERIS\n",
      "DDI\n",
      "TEI\n",
      "e-GMS\n",
      "FHIR\n",
      "DataCite\n",
      "PDB\n",
      "SensorML\n",
      "SDMX\n",
      "EngMeta\n",
      "CoverageJSON\n",
      "C-CDA\n",
      "ISO19115\n",
      "DublinCore\n",
      "OLAC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mongo_client = MongoClient(\"localhost:27017\")\n",
    "base_path=\".\"\n",
    "model_dict={}\n",
    "model_examples_folder = list(os.walk(base_path))[0][1]\n",
    "for model_name in model_examples_folder:\n",
    "    print(model_name)\n",
    "    file_list=[]\n",
    "    mongodb_coll_var = mongo_client[model_name].interop_metadata\n",
    "\n",
    "    for i in os.walk(model_name):\n",
    "        for j in i[2]:\n",
    "            if j.endswith(\".json\"):\n",
    "                file_path=os.path.join(i[0],j)\n",
    "                file_list.append((os.path.join(i[0],j),model_name,\"json\"))\n",
    "                read_preprocess_insert_in_mongodb_json(file_path, mongodb_coll=mongodb_coll_var)\n",
    "            if j.endswith(\".xml\"):\n",
    "                try:\n",
    "                    file_list.append((os.path.join(i[0],j),model_name,\"xml\"))\n",
    "                    file = etree.parse(open(os.path.join(i[0],j)), parser=etree.XMLParser(ns_clean=True, remove_comments=True, recover=True)).getroot()\n",
    "                    res = XML_to_dict(file)\n",
    "                    read_preprocess_insert_in_mongodb_json(res, mongodb_coll=mongodb_coll_var, fp_is_dict=True)\n",
    "                except Exception as e:\n",
    "                    print(os.path.join(i[0],j))\n",
    "                    print(e)\n",
    "    model_dict[model_name]=file_list\n",
    "\n",
    "\n",
    "\n",
    "# pd.DataFrame(model_dict[\"FHIR\"],columns=[\"Filepath\",\"Model\",\"File extension\"])\n",
    "\n",
    "# model_dict\n",
    "for model_name in model_dict:\n",
    "    mongodb_coll_var = mongo_client[model_name].interop_metadata\n",
    "    model_key_set=[]\n",
    "    model_key_set=set(model_key_set)\n",
    "    docs=mongodb_coll_var.find()\n",
    "    for doc in docs:\n",
    "        model_key_set = model_key_set.union(set(get_all_keys(doc, separator=\".\", key_list=[])))\n",
    "    distinct_keys = {}\n",
    "    for key in model_key_set:\n",
    "        if key != \"_id\":\n",
    "            value_filled=False\n",
    "            value = mongodb_coll_var.distinct(key)\n",
    "            for obj in value:\n",
    "                if isinstance(obj, type({})):\n",
    "\n",
    "                    value_filled = True\n",
    "                    break\n",
    "            if not value_filled:\n",
    "                distinct_keys[key]={\n",
    "                    \"count\":mongodb_coll_var.count_documents({key:{\"$exists\":True}}),\n",
    "                    \"values\": value\n",
    "                }\n",
    "    pd.DataFrame(distinct_keys).transpose().to_csv(model_name+\"_model.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T15:44:26.607319083Z",
     "start_time": "2023-09-18T15:44:20.655905530Z"
    }
   },
   "id": "1b4fb168042865d6"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "matches = pd.read_csv(\"../../matchings/structural_manual_matching.csv\")\n",
    "# matches\n",
    "res_list=[]\n",
    "for row in matches.iloc:\n",
    "    # for i in enumerate(row) : \n",
    "        # print(i, type(i))\n",
    "    matches_list = ([(matches.keys()[x[0]],x[1]) for x in enumerate(row) if not pd.isna(x[1])])\n",
    "    res_list += (list(combinations(matches_list, r=2)))\n",
    "\n",
    "pd.DataFrame(res_list,columns=[\"model_A\",\"model_B\"]).to_csv(\"../../struct_matchings_list.csv\",index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T15:47:49.895205844Z",
     "start_time": "2023-09-18T15:47:49.853656797Z"
    }
   },
   "id": "af8ada3cd8743036"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92eb350b26cb86a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
